{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-31T18:21:04.352836Z",
     "start_time": "2025-10-31T18:21:04.341818Z"
    }
   },
   "source": [
    "training_data = [\n",
    "    [(\"The\", \"DET\"), (\"dog\", \"NOUN\"), (\"barks\", \"VERB\")],\n",
    "    [(\"The\", \"DET\"), (\"cat\", \"NOUN\"), (\"meows\", \"VERB\")],\n",
    "    [(\"A\", \"DET\"), (\"dog\", \"NOUN\"), (\"runs\", \"VERB\")],\n",
    "    [(\"The\", \"DET\"), (\"dog\", \"NOUN\"), (\"runs\", \"VERB\")],\n",
    "    [(\"A\", \"DET\"), (\"cat\", \"NOUN\"), (\"sleeps\", \"VERB\")],\n",
    "    [(\"The\", \"DET\"), (\"big\", \"ADJ\"), (\"dog\", \"NOUN\"), (\"barks\", \"VERB\")],\n",
    "    [(\"A\", \"DET\"), (\"small\", \"ADJ\"), (\"cat\", \"NOUN\"), (\"meows\", \"VERB\")],\n",
    "    [(\"The\", \"DET\"), (\"dog\", \"NOUN\"), (\"sleeps\", \"VERB\")],\n",
    "    [(\"The\", \"DET\"), (\"cat\", \"NOUN\"), (\"runs\", \"VERB\")],\n",
    "    [(\"A\", \"DET\"), (\"big\", \"ADJ\"), (\"dog\", \"NOUN\"), (\"sleeps\", \"VERB\")],\n",
    "    [(\"The\", \"DET\"), (\"small\", \"ADJ\"), (\"cat\", \"NOUN\"), (\"runs\", \"VERB\")],\n",
    "    [(\"Dogs\", \"NOUN\"), (\"bark\", \"VERB\")],\n",
    "    [(\"Cats\", \"NOUN\"), (\"meow\", \"VERB\")],\n",
    "    [(\"The\", \"DET\"), (\"dog\", \"NOUN\"), (\"in\", \"ADP\"), (\"the\", \"DET\"), (\"house\", \"NOUN\"), (\"barks\", \"VERB\")],\n",
    "    [(\"A\", \"DET\"), (\"cat\", \"NOUN\"), (\"on\", \"ADP\"), (\"the\", \"DET\"), (\"mat\", \"NOUN\"), (\"sleeps\", \"VERB\")],\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T18:21:04.361328Z",
     "start_time": "2025-10-31T18:21:04.357729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "POS_list = []\n",
    "for i in range(len(training_data)):\n",
    "    for j in range(len(training_data[i])):\n",
    "        if training_data[i][j][1] not in POS_list:\n",
    "            POS_list.append(training_data[i][j][1])\n",
    "\n",
    "print(POS_list)"
   ],
   "id": "69e9759a95334f08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DET', 'NOUN', 'VERB', 'ADJ', 'ADP']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T18:21:04.532537Z",
     "start_time": "2025-10-31T18:21:04.527056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def initial_prob(training_data):\n",
    "    prob = [1 for _ in range(len(POS_list))]\n",
    "    initial_prob_dict = dict(zip(POS_list, prob))\n",
    "    for i in range(len(training_data)):\n",
    "        initial_prob_dict[training_data[i][0][1]] += 1\n",
    "    for tag, prob in initial_prob_dict.items():\n",
    "        initial_prob_dict[tag]= prob/(len(training_data) + len(POS_list))\n",
    "    return initial_prob_dict\n",
    "\n",
    "i_p = initial_prob(training_data)\n",
    "print(i_p)"
   ],
   "id": "e70684805cf78233",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DET': 0.7, 'NOUN': 0.15, 'VERB': 0.05, 'ADJ': 0.05, 'ADP': 0.05}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T18:21:04.543049Z",
     "start_time": "2025-10-31T18:21:04.538374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tag_count(training_data):\n",
    "    tag_count_dict = {tag: 0 for tag in POS_list}\n",
    "    for i in range(len(training_data)):\n",
    "        for j in range(len(training_data[i])):\n",
    "            if training_data[i][j][1] in POS_list:\n",
    "                tag_count_dict[training_data[i][j][1]] += 1\n",
    "    return tag_count_dict\n",
    "\n",
    "tag_count_result = tag_count(training_data)\n",
    "print(tag_count_result)"
   ],
   "id": "c2d3a2e0310e2511",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DET': 15, 'NOUN': 17, 'VERB': 15, 'ADJ': 4, 'ADP': 2}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T18:21:04.564922Z",
     "start_time": "2025-10-31T18:21:04.557941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def transition_prob(training_data, tag_count_dict):\n",
    "    transition_prob_dict = {t1: {t2: 1 for t2 in POS_list} for t1 in POS_list}\n",
    "    for i in range(len(training_data)):\n",
    "        for j in range(1, len(training_data[i])):\n",
    "            current = training_data[i][j][1]\n",
    "            previous = training_data[i][j - 1][1]\n",
    "            transition_prob_dict[previous][current] += 1\n",
    "    for tag_p, tag_c in transition_prob_dict.items():\n",
    "        for tag, prob in tag_c.items():\n",
    "            tag_c[tag] = prob/(tag_count_dict[tag_p] + len(POS_list))\n",
    "    return transition_prob_dict\n",
    "\n",
    "transition_prob_result = transition_prob(training_data, tag_count(training_data))\n",
    "for i, j in transition_prob_result.items():\n",
    "    print(f\"'{i}': {j}\")"
   ],
   "id": "213efe98c8424cc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'DET': {'DET': 0.05, 'NOUN': 0.6, 'VERB': 0.05, 'ADJ': 0.25, 'ADP': 0.05}\n",
      "'NOUN': {'DET': 0.045454545454545456, 'NOUN': 0.045454545454545456, 'VERB': 0.7272727272727273, 'ADJ': 0.045454545454545456, 'ADP': 0.13636363636363635}\n",
      "'VERB': {'DET': 0.05, 'NOUN': 0.05, 'VERB': 0.05, 'ADJ': 0.05, 'ADP': 0.05}\n",
      "'ADJ': {'DET': 0.1111111111111111, 'NOUN': 0.5555555555555556, 'VERB': 0.1111111111111111, 'ADJ': 0.1111111111111111, 'ADP': 0.1111111111111111}\n",
      "'ADP': {'DET': 0.42857142857142855, 'NOUN': 0.14285714285714285, 'VERB': 0.14285714285714285, 'ADJ': 0.14285714285714285, 'ADP': 0.14285714285714285}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T18:21:04.584613Z",
     "start_time": "2025-10-31T18:21:04.579361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def unique_words(training_data):\n",
    "    unique_words_list = []\n",
    "    for i in range(len(training_data)):\n",
    "        for j in range(len(training_data[i])):\n",
    "            if training_data[i][j][0] not in unique_words_list:\n",
    "                unique_words_list.append(training_data[i][j][0])\n",
    "    return unique_words_list\n",
    "\n",
    "vocab_list = unique_words(training_data)\n",
    "print(vocab_list)"
   ],
   "id": "75846ec95c6c1c64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'dog', 'barks', 'cat', 'meows', 'A', 'runs', 'sleeps', 'big', 'small', 'Dogs', 'bark', 'Cats', 'meow', 'in', 'the', 'house', 'on', 'mat']\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T18:21:04.604517Z",
     "start_time": "2025-10-31T18:21:04.599450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def emission_prob(training_data, tag_count_dict, unique_words_list):\n",
    "    emission_prob_dict = {t1: {w: 1 for w in unique_words_list} for t1 in POS_list}\n",
    "    for i in range(len(training_data)):\n",
    "        for j in range(len(training_data[i])):\n",
    "            word = training_data[i][j][0]\n",
    "            tag = training_data[i][j][1]\n",
    "            if word in emission_prob_dict[tag]:\n",
    "                emission_prob_dict[tag][word] += 1\n",
    "    for tag, word_probs in emission_prob_dict.items():\n",
    "        for word, prob in word_probs.items():\n",
    "            emission_prob_dict[tag][word] = prob/(tag_count_dict[tag] + len(unique_words_list))\n",
    "    return emission_prob_dict\n",
    "\n",
    "emission_prob_result = emission_prob(training_data, tag_count(training_data), vocab_list)\n",
    "for i, j in emission_prob_result.items():\n",
    "    print(f\"'{i}': {j}\")"
   ],
   "id": "843420a277eb5b4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'DET': {'The': 0.2647058823529412, 'dog': 0.029411764705882353, 'barks': 0.029411764705882353, 'cat': 0.029411764705882353, 'meows': 0.029411764705882353, 'A': 0.17647058823529413, 'runs': 0.029411764705882353, 'sleeps': 0.029411764705882353, 'big': 0.029411764705882353, 'small': 0.029411764705882353, 'Dogs': 0.029411764705882353, 'bark': 0.029411764705882353, 'Cats': 0.029411764705882353, 'meow': 0.029411764705882353, 'in': 0.029411764705882353, 'the': 0.08823529411764706, 'house': 0.029411764705882353, 'on': 0.029411764705882353, 'mat': 0.029411764705882353}\n",
      "'NOUN': {'The': 0.027777777777777776, 'dog': 0.2222222222222222, 'barks': 0.027777777777777776, 'cat': 0.19444444444444445, 'meows': 0.027777777777777776, 'A': 0.027777777777777776, 'runs': 0.027777777777777776, 'sleeps': 0.027777777777777776, 'big': 0.027777777777777776, 'small': 0.027777777777777776, 'Dogs': 0.05555555555555555, 'bark': 0.027777777777777776, 'Cats': 0.05555555555555555, 'meow': 0.027777777777777776, 'in': 0.027777777777777776, 'the': 0.027777777777777776, 'house': 0.05555555555555555, 'on': 0.027777777777777776, 'mat': 0.05555555555555555}\n",
      "'VERB': {'The': 0.029411764705882353, 'dog': 0.029411764705882353, 'barks': 0.11764705882352941, 'cat': 0.029411764705882353, 'meows': 0.08823529411764706, 'A': 0.029411764705882353, 'runs': 0.14705882352941177, 'sleeps': 0.14705882352941177, 'big': 0.029411764705882353, 'small': 0.029411764705882353, 'Dogs': 0.029411764705882353, 'bark': 0.058823529411764705, 'Cats': 0.029411764705882353, 'meow': 0.058823529411764705, 'in': 0.029411764705882353, 'the': 0.029411764705882353, 'house': 0.029411764705882353, 'on': 0.029411764705882353, 'mat': 0.029411764705882353}\n",
      "'ADJ': {'The': 0.043478260869565216, 'dog': 0.043478260869565216, 'barks': 0.043478260869565216, 'cat': 0.043478260869565216, 'meows': 0.043478260869565216, 'A': 0.043478260869565216, 'runs': 0.043478260869565216, 'sleeps': 0.043478260869565216, 'big': 0.13043478260869565, 'small': 0.13043478260869565, 'Dogs': 0.043478260869565216, 'bark': 0.043478260869565216, 'Cats': 0.043478260869565216, 'meow': 0.043478260869565216, 'in': 0.043478260869565216, 'the': 0.043478260869565216, 'house': 0.043478260869565216, 'on': 0.043478260869565216, 'mat': 0.043478260869565216}\n",
      "'ADP': {'The': 0.047619047619047616, 'dog': 0.047619047619047616, 'barks': 0.047619047619047616, 'cat': 0.047619047619047616, 'meows': 0.047619047619047616, 'A': 0.047619047619047616, 'runs': 0.047619047619047616, 'sleeps': 0.047619047619047616, 'big': 0.047619047619047616, 'small': 0.047619047619047616, 'Dogs': 0.047619047619047616, 'bark': 0.047619047619047616, 'Cats': 0.047619047619047616, 'meow': 0.047619047619047616, 'in': 0.09523809523809523, 'the': 0.047619047619047616, 'house': 0.047619047619047616, 'on': 0.09523809523809523, 'mat': 0.047619047619047616}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T20:53:16.409572Z",
     "start_time": "2025-10-31T20:53:16.380686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "class HMMPOSTagger:\n",
    "    def __init__(self):\n",
    "        self.POS =[]\n",
    "        self.vocab = []\n",
    "        self.initial_prob = {}\n",
    "        self.transition_prob = {}\n",
    "        self.emission_prob = {}\n",
    "        self.tag_count = {}\n",
    "\n",
    "    def train(self, training_data):\n",
    "        self.POS = list({tag for sentence in training_data for _, tag in sentence})\n",
    "        self.vocab = unique_words(training_data)\n",
    "        self.tag_count = tag_count(training_data)\n",
    "        self.initial_prob = initial_prob(training_data)\n",
    "        self.transition_prob = transition_prob(training_data, self.tag_count)\n",
    "        self.emission_prob = emission_prob(training_data, self.tag_count, self.vocab)\n",
    "\n",
    "    def generate_tag_sequence(self, current_sequence, index, sentence, all_sequences):\n",
    "        if index == len(sentence):\n",
    "            all_sequences.append(current_sequence[:])\n",
    "            return\n",
    "        for tag in self.POS:\n",
    "            current_sequence.append(tag)\n",
    "            self.generate_tag_sequence(current_sequence, index + 1, sentence, all_sequences)\n",
    "            current_sequence.pop()\n",
    "\n",
    "    def brute_force_decode(self, sentence):\n",
    "        all_sequences = []\n",
    "        self.generate_tag_sequence([], 0, sentence, all_sequences)\n",
    "        best_tags = None\n",
    "        best_prob = 0\n",
    "        for tags in all_sequences:\n",
    "            prob = self.initial_prob[tags[0]] * self.emission_prob[tags[0]].get(sentence[0], 1e-6)\n",
    "            for i in range(1, len(sentence)):\n",
    "                prev_tag = tags[i - 1]\n",
    "                curr_tag = tags[i]\n",
    "                word = sentence[i]\n",
    "                prob *= self.transition_prob[prev_tag][curr_tag] * self.emission_prob[curr_tag].get(word, 1e-6)\n",
    "            if prob > best_prob:\n",
    "                best_prob = prob\n",
    "                best_tags = tags\n",
    "        return list(best_tags)\n",
    "\n",
    "\n",
    "    def viterbi_decode(self, sentence):\n",
    "        V = []\n",
    "        backpointer = []\n",
    "\n",
    "        first_probs = {}\n",
    "        first_back = {}\n",
    "\n",
    "        for tag in self.POS:\n",
    "            emission = self.emission_prob[tag].get(sentence[0], 1e-6)\n",
    "            first_probs[tag] = math.log(self.initial_prob[tag]) + math.log(emission)\n",
    "            first_back[tag] = None\n",
    "\n",
    "        V.append(first_probs)\n",
    "        backpointer.append(first_back)\n",
    "\n",
    "        for i in range(1, len(sentence)):\n",
    "            current_probs = {}\n",
    "            current_back = {}\n",
    "            word = sentence[i]\n",
    "\n",
    "            for tag in self.POS:\n",
    "                max_prob = float(\"-inf\")\n",
    "                best_prev_tag = None\n",
    "\n",
    "                for prev_tag in self.POS:\n",
    "                    transition = self.transition_prob[prev_tag][tag]\n",
    "                    emission = self.emission_prob[tag].get(word, 1e-6)\n",
    "\n",
    "                    prob = V[i - 1][prev_tag] + math.log(transition) + math.log(emission)\n",
    "\n",
    "                    if prob > max_prob:\n",
    "                        max_prob = prob\n",
    "                        best_prev_tag = prev_tag\n",
    "\n",
    "                current_probs[tag] = max_prob\n",
    "                current_back[tag] = best_prev_tag\n",
    "\n",
    "            V.append(current_probs)\n",
    "            backpointer.append(current_back)\n",
    "\n",
    "        best_last_tag = None\n",
    "        best_last_prob = float(\"-inf\")\n",
    "\n",
    "        for tag in self.POS:\n",
    "            if V[-1][tag] > best_last_prob:\n",
    "                best_last_prob = V[-1][tag]\n",
    "                best_last_tag = tag\n",
    "\n",
    "        best_tags = [best_last_tag]\n",
    "        for i in range(len(sentence) - 1, 0, -1):\n",
    "            best_tags.append(backpointer[i][best_tags[-1]])\n",
    "\n",
    "\n",
    "        best_tags.reverse()\n",
    "        return best_tags\n"
   ],
   "id": "d1a3e0944b900102",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T20:53:20.445154Z",
     "start_time": "2025-10-31T20:53:20.437924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tagger = HMMPOSTagger()\n",
    "tagger.train(training_data)"
   ],
   "id": "4e30ad083a2cf50a",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T20:55:14.419058Z",
     "start_time": "2025-10-31T20:55:14.365474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_sentences = [\n",
    "    [\"The\", \"dog\", \"barks\"],\n",
    "    [\"A\", \"cat\", \"sleeps\"],\n",
    "    [\"The\", \"big\", \"dog\", \"runs\"],\n",
    "    [\"Dogs\", \"bark\"],\n",
    "    # New sentences\n",
    "    [\"Little\", \"bird\", \"sings\"],\n",
    "    [\"The\", \"little\", \"boy\", \"runs\", \"quickly\"],\n",
    "    [\"The\", \"sun\", \"shines\"],\n",
    "    [\"A\", \"tiny\", \"mouse\", \"eats\", \"cheese\"],\n",
    "    [\"The\", \"happy\", \"dog\", \"plays\", \"outside\"],\n",
    "    [\"Cats\", \"jump\", \"high\"],\n",
    "    [\"The\", \"girl\", \"reads\", \"a\", \"book\"],\n",
    "    [\"A\", \"beautiful\", \"flower\", \"blooms\", \"today\"]\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Brute force:\", tagger.brute_force_decode(sentence))\n",
    "    print(\"Viterbi:\", tagger.viterbi_decode(sentence))\n",
    "    print()"
   ],
   "id": "f8f4e69940c65c1a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: ['The', 'dog', 'barks']\n",
      "Brute force: ['DET', 'NOUN', 'VERB']\n",
      "Viterbi: ['DET', 'NOUN', 'VERB']\n",
      "\n",
      "Sentence: ['A', 'cat', 'sleeps']\n",
      "Brute force: ['DET', 'NOUN', 'VERB']\n",
      "Viterbi: ['DET', 'NOUN', 'VERB']\n",
      "\n",
      "Sentence: ['The', 'big', 'dog', 'runs']\n",
      "Brute force: ['DET', 'ADJ', 'NOUN', 'VERB']\n",
      "Viterbi: ['DET', 'ADJ', 'NOUN', 'VERB']\n",
      "\n",
      "Sentence: ['Dogs', 'bark']\n",
      "Brute force: ['NOUN', 'VERB']\n",
      "Viterbi: ['NOUN', 'VERB']\n",
      "\n",
      "Sentence: ['Little', 'bird', 'sings']\n",
      "Brute force: ['DET', 'NOUN', 'VERB']\n",
      "Viterbi: ['DET', 'NOUN', 'VERB']\n",
      "\n",
      "Sentence: ['The', 'little', 'boy', 'runs', 'quickly']\n",
      "Brute force: ['DET', 'ADJ', 'NOUN', 'VERB', 'ADJ']\n",
      "Viterbi: ['DET', 'ADJ', 'NOUN', 'VERB', 'ADJ']\n",
      "\n",
      "Sentence: ['The', 'sun', 'shines']\n",
      "Brute force: ['DET', 'NOUN', 'VERB']\n",
      "Viterbi: ['DET', 'NOUN', 'VERB']\n",
      "\n",
      "Sentence: ['A', 'tiny', 'mouse', 'eats', 'cheese']\n",
      "Brute force: ['DET', 'NOUN', 'ADP', 'DET', 'NOUN']\n",
      "Viterbi: ['DET', 'NOUN', 'ADP', 'DET', 'NOUN']\n",
      "\n",
      "Sentence: ['The', 'happy', 'dog', 'plays', 'outside']\n",
      "Brute force: ['DET', 'ADJ', 'NOUN', 'ADP', 'DET']\n",
      "Viterbi: ['DET', 'ADJ', 'NOUN', 'ADP', 'DET']\n",
      "\n",
      "Sentence: ['Cats', 'jump', 'high']\n",
      "Brute force: ['DET', 'NOUN', 'VERB']\n",
      "Viterbi: ['DET', 'NOUN', 'VERB']\n",
      "\n",
      "Sentence: ['The', 'girl', 'reads', 'a', 'book']\n",
      "Brute force: ['DET', 'NOUN', 'ADP', 'DET', 'NOUN']\n",
      "Viterbi: ['DET', 'NOUN', 'ADP', 'DET', 'NOUN']\n",
      "\n",
      "Sentence: ['A', 'beautiful', 'flower', 'blooms', 'today']\n",
      "Brute force: ['DET', 'NOUN', 'ADP', 'DET', 'NOUN']\n",
      "Viterbi: ['DET', 'NOUN', 'ADP', 'DET', 'NOUN']\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
