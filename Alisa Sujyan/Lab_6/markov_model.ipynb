{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data cleaning, preprocessing",
   "id": "94c2438bc38c73a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T01:09:53.623333Z",
     "start_time": "2025-10-11T01:09:53.605999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def cleaned_text(text):\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r'[\\\"\\',;.:?!()<>-]', '', text)\n",
    "    return text"
   ],
   "id": "a48b6af5e8c1d66d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T01:09:58.703158Z",
     "start_time": "2025-10-11T01:09:58.639839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"robert_frost.txt\", \"r\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "with open(\"preprocessed.txt\", \"w\") as file:\n",
    "\n",
    "    for line in text.splitlines():\n",
    "        line = cleaned_text(line)\n",
    "        if line:\n",
    "            file.write(line + \" <END>\\n\")"
   ],
   "id": "c09794316282df4c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T01:09:58.912129Z",
     "start_time": "2025-10-11T01:09:58.877107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_sentences = []\n",
    "\n",
    "with open(\"preprocessed.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        words = line.split()\n",
    "        if words:\n",
    "            tokenized_sentences.append(words)\n",
    "\n",
    "print(tokenized_sentences[:5])\n",
    "print(len(tokenized_sentences))"
   ],
   "id": "f237ec6e902ebaac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['two', 'roads', 'diverged', 'in', 'a', 'yellow', 'wood', '<END>'], ['and', 'sorry', 'i', 'could', 'not', 'travel', 'both', '<END>'], ['and', 'be', 'one', 'traveler', 'long', 'i', 'stood', '<END>'], ['and', 'looked', 'down', 'one', 'as', 'far', 'as', 'i', 'could', '<END>'], ['to', 'where', 'it', 'bent', 'in', 'the', 'undergrowth', '<END>']]\n",
      "1436\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Initial word probabilities",
   "id": "4068c1a0d1da5c70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T01:10:05.566839Z",
     "start_time": "2025-10-11T01:10:05.549382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lines_total_count = len(tokenized_sentences)\n",
    "initial_prob = {}\n",
    "\n",
    "for line in tokenized_sentences:\n",
    "    initial_prob[line[0]] = initial_prob.get(line[0], 0) + 1\n",
    "\n",
    "for word in initial_prob:\n",
    "    initial_prob[word] /= lines_total_count\n",
    "\n",
    "print(dict(list(initial_prob.items())[:10]))\n",
    "print(len(initial_prob))"
   ],
   "id": "c3f4d01315f01b54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'two': 0.005571030640668524, 'and': 0.08983286908077995, 'to': 0.034818941504178275, 'then': 0.008356545961002786, 'because': 0.0006963788300835655, 'though': 0.004874651810584958, 'had': 0.002785515320334262, 'in': 0.0201949860724234, 'oh': 0.002785515320334262, 'yet': 0.0020891364902506965}\n",
      "305\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### First-order transitions\n",
   "id": "3c6bd92837e1b7ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T01:10:09.861309Z",
     "start_time": "2025-10-11T01:10:09.819526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "first_order = {}\n",
    "first_order_prob = {}\n",
    "\n",
    "for line in tokenized_sentences:\n",
    "    for i in range(len(line)-1):\n",
    "        previous = line[i]\n",
    "        current = line[i+1]\n",
    "\n",
    "        if previous not in first_order:\n",
    "            first_order[previous] = {}\n",
    "\n",
    "        if current not in first_order[previous]:\n",
    "            first_order[previous][current] = 0\n",
    "\n",
    "        first_order[previous][current] += 1\n",
    "\n",
    "for previous, current in first_order.items():\n",
    "    total = sum(current.values())\n",
    "    first_order_prob[previous] = {current:count/total for current, count in current.items()}\n",
    "\n",
    "print(dict(list(first_order_prob.items())[:4]))"
   ],
   "id": "76c94434c163d5e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'two': {'roads': 0.1111111111111111, 'miles': 0.05555555555555555, 'towns': 0.05555555555555555, 'converging': 0.05555555555555555, 'or': 0.05555555555555555, 'oldbelievers': 0.05555555555555555, 'legs': 0.05555555555555555, 'footsteps': 0.05555555555555555, '<END>': 0.1111111111111111, 'village': 0.05555555555555555, 'winds': 0.05555555555555555, 'weeks': 0.05555555555555555, 'of': 0.05555555555555555, 'as': 0.05555555555555555, 'at': 0.05555555555555555, 'oclock': 0.05555555555555555}, 'roads': {'diverged': 1.0}, 'diverged': {'in': 1.0}, 'in': {'a': 0.08383233532934131, 'the': 0.2754491017964072, 'leaves': 0.005988023952095809, 'fire': 0.005988023952095809, 'ice': 0.005988023952095809, 'rain': 0.041916167664670656, 'front': 0.017964071856287425, 'every': 0.017964071856287425, 'it': 0.03592814371257485, 'winter': 0.011976047904191617, 'somewhere': 0.005988023952095809, 'march': 0.005988023952095809, 'warren': 0.011976047904191617, '<END>': 0.011976047904191617, 'wentworth': 0.005988023952095809, 'their': 0.011976047904191617, 'his': 0.017964071856287425, 'grafton': 0.005988023952095809, 'and': 0.011976047904191617, 'folks': 0.005988023952095809, 'dalton': 0.005988023952095809, 'eightyfive': 0.005988023952095809, 'dust': 0.005988023952095809, 'for': 0.005988023952095809, 'bed': 0.017964071856287425, 'flight': 0.005988023952095809, 'stones': 0.005988023952095809, 'virgin': 0.005988023952095809, 'one': 0.017964071856287425, 'another': 0.005988023952095809, 'my': 0.005988023952095809, 'heaven': 0.005988023952095809, 'time': 0.005988023952095809, 'at': 0.011976047904191617, 'snow': 0.011976047904191617, 'its': 0.005988023952095809, 'spring': 0.005988023952095809, 'me': 0.005988023952095809, 'life': 0.005988023952095809, 'all': 0.005988023952095809, 'her': 0.017964071856287425, 'summer': 0.005988023952095809, 'going': 0.005988023952095809, 'new': 0.005988023952095809, 'bow': 0.005988023952095809, 'an': 0.011976047904191617, 'town': 0.005988023952095809, 'grove': 0.005988023952095809, 'detail': 0.005988023952095809, 'starkness': 0.005988023952095809, 'trees': 0.005988023952095809, 'such': 0.017964071856287425, 'trains': 0.005988023952095809, 'among': 0.005988023952095809, 'across': 0.005988023952095809, 'dialect': 0.005988023952095809, 'not': 0.005988023952095809, 'this': 0.005988023952095809, 'sunshine': 0.005988023952095809, 'building': 0.005988023952095809, 'air': 0.005988023952095809, 'position': 0.005988023952095809, 'your': 0.005988023952095809, 'dough': 0.005988023952095809, 'earnest': 0.011976047904191617, 'that': 0.023952095808383235, 'creation': 0.005988023952095809, 'than': 0.005988023952095809, 'here': 0.005988023952095809, 'year': 0.005988023952095809, 'separate': 0.005988023952095809, 'ways': 0.005988023952095809}}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Second-order transitions",
   "id": "d3e089cb1246c3eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T01:10:14.087626Z",
     "start_time": "2025-10-11T01:10:13.943787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "second_order = {}\n",
    "second_order_prob = {}\n",
    "\n",
    "for line in tokenized_sentences:\n",
    "    for i in range(2, len(line)):\n",
    "        previous_previous = line[i - 2]\n",
    "        previous = line[i - 1]\n",
    "        current = line[i]\n",
    "\n",
    "        key = (previous_previous, previous)\n",
    "\n",
    "        if key not in second_order:\n",
    "            second_order[key] = {}\n",
    "\n",
    "        if current not in second_order[key]:\n",
    "            second_order[key][current] = 0\n",
    "\n",
    "        second_order[key][current] += 1\n",
    "\n",
    "for key, current in second_order.items():\n",
    "    total = sum(current.values())\n",
    "    second_order_prob[key] = {word: count / total for word, count in current.items()}\n",
    "\n",
    "print(dict(list(second_order_prob.items())[:5]))"
   ],
   "id": "c3dec4f18027f874",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('two', 'roads'): {'diverged': 1.0}, ('roads', 'diverged'): {'in': 1.0}, ('diverged', 'in'): {'a': 1.0}, ('in', 'a'): {'yellow': 0.07142857142857142, 'wood': 0.07142857142857142, 'window': 0.07142857142857142, 'packing': 0.07142857142857142, 'byroad': 0.07142857142857142, 'family': 0.07142857142857142, 'new': 0.07142857142857142, 'row': 0.07142857142857142, 'time': 0.07142857142857142, 'town': 0.07142857142857142, 'book': 0.07142857142857142, 'smother': 0.07142857142857142, 'glass': 0.14285714285714285}, ('a', 'yellow'): {'wood': 1.0}}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Cumulative probability method",
   "id": "899da1e880618afd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T00:55:48.166846Z",
     "start_time": "2025-10-11T00:55:48.158546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "def cumulative_prob(prob_dict):\n",
    "\n",
    "    r = random.random()\n",
    "    cumulative = 0.0\n",
    "\n",
    "    for word, probability in prob_dict.items():\n",
    "        cumulative += probability\n",
    "        if r <= cumulative:\n",
    "            return word"
   ],
   "id": "8d6c035f7764935d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T00:55:48.850617Z",
     "start_time": "2025-10-11T00:55:48.845169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def markov_model(initial_prob, first_order_prob, second_order_prob):\n",
    "    sentence = []\n",
    "\n",
    "    w1 = cumulative_prob(initial_prob)\n",
    "    sentence.append(w1)\n",
    "\n",
    "    w2 = cumulative_prob(first_order_prob[w1])\n",
    "    sentence.append(w2)\n",
    "\n",
    "    while True:\n",
    "        key = (sentence[-2], sentence[-1])\n",
    "        if key not in second_order_prob:\n",
    "            break\n",
    "\n",
    "        next_word = cumulative_prob(second_order_prob[key])\n",
    "        if next_word == \"<END>\":\n",
    "            break\n",
    "\n",
    "        sentence.append(next_word)\n",
    "\n",
    "\n",
    "    return sentence"
   ],
   "id": "25df70c659af21ca",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T00:57:33.350798Z",
     "start_time": "2025-10-11T00:57:33.331393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(10):\n",
    "    sentence = markov_model(initial_prob, first_order_prob, second_order_prob)\n",
    "    print(f\"{i+1}\", ' '.join(sentence))"
   ],
   "id": "f71921fdffd3ac9e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 first let me see\n",
      "2 i heard him downstairs in the box\n",
      "3 but saved the light and see what they always were\n",
      "4 i see raspberry vines\n",
      "5 some magic of the train and go back\n",
      "6 but when i go up through the mowing field\n",
      "7 something brushed across my mind\n",
      "8 and turn doll out to sun and romp\n",
      "9 the grave\n",
      "10 how are you neighbour just the same as you throw a picture on a sort of swear the time being\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
