{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data cleaning, preprocessing",
   "id": "4dac86093d5eab39"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-11T01:17:36.234660Z",
     "start_time": "2025-10-11T01:17:36.225767Z"
    }
   },
   "source": [
    "import re\n",
    "\n",
    "def cleaned_text(text):\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r'[\\\"\\',;.:?!()<>-]', '', text)\n",
    "    return text"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T01:17:41.145626Z",
     "start_time": "2025-10-11T01:17:41.114411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"robert_frost.txt\", \"r\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "with open(\"preprocessed.txt\", \"w\") as file:\n",
    "\n",
    "    for line in text.splitlines():\n",
    "        line = cleaned_text(line)\n",
    "        if line:\n",
    "            file.write(line + \" <END>\\n\")"
   ],
   "id": "d295264b981f1c72",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T01:17:42.383805Z",
     "start_time": "2025-10-11T01:17:42.367861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_sentences = []\n",
    "\n",
    "with open(\"preprocessed.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        words = line.split()\n",
    "        if words:\n",
    "            tokenized_sentences.append(words)\n",
    "\n",
    "print(tokenized_sentences[:5])\n",
    "print(len(tokenized_sentences))"
   ],
   "id": "2b4ce1e5c0db6d5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['two', 'roads', 'diverged', 'in', 'a', 'yellow', 'wood', '<END>'], ['and', 'sorry', 'i', 'could', 'not', 'travel', 'both', '<END>'], ['and', 'be', 'one', 'traveler', 'long', 'i', 'stood', '<END>'], ['and', 'looked', 'down', 'one', 'as', 'far', 'as', 'i', 'could', '<END>'], ['to', 'where', 'it', 'bent', 'in', 'the', 'undergrowth', '<END>']]\n",
      "1436\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Initial word probabilities\n",
   "id": "c6ab379f47bb7021"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T01:17:51.425835Z",
     "start_time": "2025-10-11T01:17:51.418884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lines_total_count = len(tokenized_sentences)\n",
    "initial_prob = {}\n",
    "\n",
    "for line in tokenized_sentences:\n",
    "    initial_prob[line[0]] = initial_prob.get(line[0], 0) + 1\n",
    "\n",
    "for word in initial_prob:\n",
    "    initial_prob[word] /= lines_total_count\n",
    "\n",
    "print(dict(list(initial_prob.items())[:10]))\n",
    "print(len(initial_prob))"
   ],
   "id": "70671d029bd86697",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'two': 0.005571030640668524, 'and': 0.08983286908077995, 'to': 0.034818941504178275, 'then': 0.008356545961002786, 'because': 0.0006963788300835655, 'though': 0.004874651810584958, 'had': 0.002785515320334262, 'in': 0.0201949860724234, 'oh': 0.002785515320334262, 'yet': 0.0020891364902506965}\n",
      "305\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### First-order transitions\n",
   "id": "b34e5aca580d40ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T01:17:59.142593Z",
     "start_time": "2025-10-11T01:17:59.127375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "first_order = {}\n",
    "first_order_prob = {}\n",
    "\n",
    "for line in tokenized_sentences:\n",
    "    for i in range(len(line)-1):\n",
    "        previous = line[i]\n",
    "        current = line[i+1]\n",
    "\n",
    "        if previous not in first_order:\n",
    "            first_order[previous] = {}\n",
    "\n",
    "        if current not in first_order[previous]:\n",
    "            first_order[previous][current] = 0\n",
    "\n",
    "        first_order[previous][current] += 1\n",
    "\n",
    "for previous, current in first_order.items():\n",
    "    total = sum(current.values())\n",
    "    first_order_prob[previous] = {current:count/total for current, count in current.items()}\n",
    "\n",
    "print(dict(list(first_order_prob.items())[:4]))"
   ],
   "id": "2090fe7051b2dba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'two': {'roads': 0.1111111111111111, 'miles': 0.05555555555555555, 'towns': 0.05555555555555555, 'converging': 0.05555555555555555, 'or': 0.05555555555555555, 'oldbelievers': 0.05555555555555555, 'legs': 0.05555555555555555, 'footsteps': 0.05555555555555555, '<END>': 0.1111111111111111, 'village': 0.05555555555555555, 'winds': 0.05555555555555555, 'weeks': 0.05555555555555555, 'of': 0.05555555555555555, 'as': 0.05555555555555555, 'at': 0.05555555555555555, 'oclock': 0.05555555555555555}, 'roads': {'diverged': 1.0}, 'diverged': {'in': 1.0}, 'in': {'a': 0.08383233532934131, 'the': 0.2754491017964072, 'leaves': 0.005988023952095809, 'fire': 0.005988023952095809, 'ice': 0.005988023952095809, 'rain': 0.041916167664670656, 'front': 0.017964071856287425, 'every': 0.017964071856287425, 'it': 0.03592814371257485, 'winter': 0.011976047904191617, 'somewhere': 0.005988023952095809, 'march': 0.005988023952095809, 'warren': 0.011976047904191617, '<END>': 0.011976047904191617, 'wentworth': 0.005988023952095809, 'their': 0.011976047904191617, 'his': 0.017964071856287425, 'grafton': 0.005988023952095809, 'and': 0.011976047904191617, 'folks': 0.005988023952095809, 'dalton': 0.005988023952095809, 'eightyfive': 0.005988023952095809, 'dust': 0.005988023952095809, 'for': 0.005988023952095809, 'bed': 0.017964071856287425, 'flight': 0.005988023952095809, 'stones': 0.005988023952095809, 'virgin': 0.005988023952095809, 'one': 0.017964071856287425, 'another': 0.005988023952095809, 'my': 0.005988023952095809, 'heaven': 0.005988023952095809, 'time': 0.005988023952095809, 'at': 0.011976047904191617, 'snow': 0.011976047904191617, 'its': 0.005988023952095809, 'spring': 0.005988023952095809, 'me': 0.005988023952095809, 'life': 0.005988023952095809, 'all': 0.005988023952095809, 'her': 0.017964071856287425, 'summer': 0.005988023952095809, 'going': 0.005988023952095809, 'new': 0.005988023952095809, 'bow': 0.005988023952095809, 'an': 0.011976047904191617, 'town': 0.005988023952095809, 'grove': 0.005988023952095809, 'detail': 0.005988023952095809, 'starkness': 0.005988023952095809, 'trees': 0.005988023952095809, 'such': 0.017964071856287425, 'trains': 0.005988023952095809, 'among': 0.005988023952095809, 'across': 0.005988023952095809, 'dialect': 0.005988023952095809, 'not': 0.005988023952095809, 'this': 0.005988023952095809, 'sunshine': 0.005988023952095809, 'building': 0.005988023952095809, 'air': 0.005988023952095809, 'position': 0.005988023952095809, 'your': 0.005988023952095809, 'dough': 0.005988023952095809, 'earnest': 0.011976047904191617, 'that': 0.023952095808383235, 'creation': 0.005988023952095809, 'than': 0.005988023952095809, 'here': 0.005988023952095809, 'year': 0.005988023952095809, 'separate': 0.005988023952095809, 'ways': 0.005988023952095809}}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Second-order transition",
   "id": "f3b663328be9e6be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T01:18:06.189660Z",
     "start_time": "2025-10-11T01:18:06.171871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "second_order = {}\n",
    "second_order_prob = {}\n",
    "\n",
    "for line in tokenized_sentences:\n",
    "    for i in range(2, len(line)):\n",
    "        previous_previous = line[i - 2]\n",
    "        previous = line[i - 1]\n",
    "        current = line[i]\n",
    "\n",
    "        key = (previous_previous, previous)\n",
    "\n",
    "        if key not in second_order:\n",
    "            second_order[key] = {}\n",
    "\n",
    "        if current not in second_order[key]:\n",
    "            second_order[key][current] = 0\n",
    "\n",
    "        second_order[key][current] += 1\n",
    "\n",
    "for key, current in second_order.items():\n",
    "    total = sum(current.values())\n",
    "    second_order_prob[key] = {word: count / total for word, count in current.items()}\n",
    "\n",
    "print(dict(list(second_order_prob.items())[:5]))"
   ],
   "id": "e2fdb647d2a9629c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('two', 'roads'): {'diverged': 1.0}, ('roads', 'diverged'): {'in': 1.0}, ('diverged', 'in'): {'a': 1.0}, ('in', 'a'): {'yellow': 0.07142857142857142, 'wood': 0.07142857142857142, 'window': 0.07142857142857142, 'packing': 0.07142857142857142, 'byroad': 0.07142857142857142, 'family': 0.07142857142857142, 'new': 0.07142857142857142, 'row': 0.07142857142857142, 'time': 0.07142857142857142, 'town': 0.07142857142857142, 'book': 0.07142857142857142, 'smother': 0.07142857142857142, 'glass': 0.14285714285714285}, ('a', 'yellow'): {'wood': 1.0}}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Cumulative probability method",
   "id": "fac5cfc05bf2c1a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T01:18:08.367535Z",
     "start_time": "2025-10-11T01:18:08.350852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "def cumulative_prob(prob_dict):\n",
    "\n",
    "    r = random.random()\n",
    "    cumulative = 0.0\n",
    "\n",
    "    for word, probability in prob_dict.items():\n",
    "        cumulative += probability\n",
    "        if r <= cumulative:\n",
    "            return word"
   ],
   "id": "4cb8deac6b1742ad",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Generation and inference",
   "id": "edfca250dc1c9484"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T01:18:09.589705Z",
     "start_time": "2025-10-11T01:18:09.580122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def markov_model(initial_prob, first_order_prob, second_order_prob):\n",
    "    sentence = []\n",
    "\n",
    "    w1 = cumulative_prob(initial_prob)\n",
    "    sentence.append(w1)\n",
    "\n",
    "    w2 = cumulative_prob(first_order_prob[w1])\n",
    "    sentence.append(w2)\n",
    "\n",
    "    while True:\n",
    "        key = (sentence[-2], sentence[-1])\n",
    "        if key not in second_order_prob:\n",
    "            break\n",
    "\n",
    "        next_word = cumulative_prob(second_order_prob[key])\n",
    "        if next_word == \"<END>\":\n",
    "            break\n",
    "\n",
    "        sentence.append(next_word)\n",
    "\n",
    "\n",
    "    return sentence"
   ],
   "id": "2fa4d965447547cf",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T01:18:56.989045Z",
     "start_time": "2025-10-11T01:18:56.979601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(10):\n",
    "    sentence = markov_model(initial_prob, first_order_prob, second_order_prob)\n",
    "    print(f\"{i+1}\", ' '.join(sentence))"
   ],
   "id": "4018813ba91a3dbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ive said why shouldnt they be married\n",
      "2 itd make my position stronger i think were all mad tell me about her does she look like me\n",
      "3 its raining\n",
      "4 he said the dead had souls but when ive done it what was either cloud or smoke\n",
      "5 from the ground\n",
      "6 legitimately my demand upon her\n",
      "7 theirs interlock\n",
      "8 that prove\n",
      "9 but it doesnt seem as if by eye pairs out of beaten ways\n",
      "10 up a cheering song of how\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
